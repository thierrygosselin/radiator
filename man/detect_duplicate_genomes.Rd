% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/detect_duplicate_genomes.R
\name{detect_duplicate_genomes}
\alias{detect_duplicate_genomes}
\title{Compute pairwise genome similarity or distance between individuals
to highligh potential duplicate individuals}
\usage{
detect_duplicate_genomes(data, subsample.markers = NULL, random.seed = NULL,
  distance.method = "manhattan", genome = FALSE,
  parallel.core = parallel::detectCores() - 1)
}
\arguments{
\item{data}{A tidy data frame object in the global environment or
a tidy data frame in wide or long format in the working directory.
\emph{How to get a tidy data frame ?}
Look into \pkg{radiator} \code{\link{tidy_genomic_data}}.}

\item{subsample.markers}{(optional, integer) To speed up computation and rapidly
test the function's arguments (e.g. using 200 markers).
Default: \code{subsample.markers = NULL}.}

\item{random.seed}{(integer, optional) For reproducibility, set an integer
for randomness when argument \code{subsample.markers} is used.
By default, a random number is generated and printed.
Default: \code{random.seed = NULL}.}

\item{distance.method}{(character) The distance measure used inside \code{stats::dist}
(<= 30000 markers) or \code{amap::Dist} (> 30000 markers).
This must be one of "euclidean", "maximum", "manhattan", "canberra", "binary".
Using \code{distance.method = NULL} will not run this method.
Default: \code{distance.method = "manhattan"}. This is very fast
compared to the genome similarity method. It uses allele counts and the codes
are tailored for biallelic and multiallelic markers.}

\item{genome}{(logical) Computes pairwise genome similarity in parallel.
The proportion of the shared genotypes is averaged across shared markers between
each pairwise comparison. This method makes filtering easier because the
threshold is more intuitive with the plots produced, but it's much longer
to run, even in parallel, so better to run overnight.
Default: \code{genome = FALSE}.}

\item{parallel.core}{(optional) The number of core for parallel computation.
Default: \code{parallel.core = parallel::detectCores() - 1}.}
}
\value{
A list with potentially 8 objects:
\code{$distance }: results of the distance method
\code{$distance.stats}: Summary statistics of the distance method
\code{$pairwise.genome.similarity}: results of the genome method
\code{$genome.stats}: Summary statistics of the genome method
\code{$violin.plot.distance}: violin plot showing the distribution of pairwise distances
\code{$manhattan.plot.distance}: same info different visual with manhattan plot
\code{$violin.plot.genome}: violin plot showing the distribution of pairwise genome similarities
\code{$manhattan.plot.genome}: same info different visual with manhattan plot
\code{$blacklist.id.similar}: blacklisted duplicates

Saved in the working directory:
individuals.pairwise.dist.tsv, individuals.pairwise.distance.stats.tsv,
individuals.pairwise.genome.similarity.tsv, individuals.pairwise.genome.stats.tsv,
blackliste.id.similar.tsv
}
\description{
The function can compute two methods
to highligh potential duplicate individuals.
\enumerate{
\item distance between individuals and/or
\item pairwise genome similarity
}
}
\details{
Strategically, run the default first (\code{distance.method},
no \code{genome})

\strong{\code{distance.method} argument is fast, but...}

you don't know if the observed comparison (close or distant)
is influenced by missing values/the number of markers in common
between the pair compared. This is something that needs to be considered.
Be suspicious of a \emph{distant outlier} from the same pop pairwise comparison,
and similarly, be suspicious of a \emph{close outlier} from a different pop
pairwise comparisons.

If there is no outlier, don't bother running the function again with
(\code{genome = TRUE}).


\strong{\code{genome = TRUE}}

The function will run slower, but...
If you see outliers with the first run, take the time to run the function
with \code{genome = TRUE}. Because this option is much better at detecting
duplicated individuals and it also shows the impact of \strong{missingness}
or the number of \strong{shared markers} between comparisons.

\emph{Your outlier duo could well be the result of one of the individual having
an extremely low number genotypes...}
}
\examples{
\dontrun{
# First run and simplest way (if you have the tidy df):
dup <- radiator::detect_duplicate_genomes(data = "wombat_tidy.tsv")

#If you need a tidy df:
dup <- radiator::tidy_genomic_data(
data = "wombat_tidy.tsv",
strata = "wombat.strata.tsv",
vcf.metadata = FALSE
) \%>\%
radiator::detect_duplicate_genomes(data = .)

# This will use by defaul:
distance.method = "manhattan"
genome = FALSE
#parallel.core = all my CPUs - 1

# To view the manhattan plot:
dup$manhattan.plot.distance

# to view the data stats
dup.data.stats <- dup$distance.stats

# to view the data
dup.data <- dup$distance

# Based on the look of the distribution using both manhattan and boxplot,
# I can filter the dataset to highlight potential duplicates.

# To run the distance (with euclidean distance instead of the default manhattan,
# and also carry the second analysis (with the genome method):
dup <- radiator::tidy_genomic_data(
data = "wombat_tidy.tsv",
strata = "wombat.strata.tsv",
vcf.metadata = FALSE
) \%>\%
radiator::detect_duplicate_genomes(data = ., distance.method = "euclidean", genome = TRUE)

# to view the data of the genome data
dup.data <- dup$pairwise.genome.similarity

# Based on the look of the distribution using both manhattan and boxplot,
# I can filter the dataset based on 98\% of identical genotype proportion,
# to highlight potential duplicates:
dup.filtered <- dplyr::filter(.data = dup.data, PROP_IDENTICAL > 0.98)

# Get the list of duplicates id
dup.list.names <- data.frame(INDIVIDUALS = unique(c(dup.filtered$ID1, dup.filtered$ID2)))
}
}
\author{
Thierry Gosselin \email{thierrygosselin@icloud.com}
}
