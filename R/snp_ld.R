#' @name snp_ld
#' @title GBS/RADseq short and long distance linkage disequilibrium pruning
#' @description SNP short and long distance linkage disequilibrium pruning.
#'
#' What sets appart radiator LD pruning is the RADseq data tailored arguments.
#' First, minimize short linkage disequilibrium (LD) by
#' choosing between 5 values for \code{snp.ld} argument (see below).
#' Second, you can optionally reduce long distance LD by adjusting the argument
#' \code{ld.threshold}. Values between 0.7 and 0.9 are good starting point.
#' You can also choose to refilter the data using the outlier statistics
#' generated by the function.
#' To prune markers in long distance LD, instead of choosing randomly one SNP,
#' radiator can incorporate missing data statistics
#' to determine the best SNP to keep (see details).
#'
#' Long distance LD pruning is usually advised to avoid capturing the variance LD
#' in PCA analysis.
#'
#' This function is used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' and might be of interest for users.

#' @param data A tidy data set with ID (LOCUS) and POS (SNP) information.
#' \emph{How to get a tidy data frame ?}
#' Look into \pkg{radiator} \code{\link{tidy_genomic_data}}.
#' Usually the LOCUS and POS info is taken from a VCF file.
#'
#' The function also accept \code{SeqVarGDSClass} object generated
#' with the SeqArray package
#' or \pkg{radiator} \code{\link{write_seqarray}}.
#'
#' \strong{Biallelic genotypes required...}


#' @param snp.ld (character) 5 options:
#' \enumerate{
#' \item \code{snp.ld = "random"} for a random selection of 1 SNP on the read,
#' \item \code{snp.ld = "first"} for the first one on the read...,
#' \item \code{snp.ld = "last"} for the last SNP on the read and
#' \item \code{snp.ld = "middle"} for locus with > 2 SNPs/read the option to select at random
#' one SNP between the first and the last SNP on the read. If the locus as <= 2
#' SNPs on the read, the first one is selected. Note that for that last option,
#' the numbers are reported.
#' \item \code{snp.ld = "maf"} will select the SNP on the locus with the maximum global
#' Minor Allele Frequency (MAF).
#' }
#' Default: \code{snp.ld = "maf"}.

#' @param maf.data (path) When \code{snp.ld = "maf"} is selected,
#' to speed up calculations, you can provide
#' the maf information generated by the function \code{\link{filter_maf}} or
#' let this function calculates it from the data (default).
#' Designated alternate allele embedded in the data are not taken for granted
#' and this information is re-computed from the data to get actual
#' minor allele frequency. In this context, to speed up calculations,
#' the MAF is calculated only for locus with multiple SNPs .
#' Default: \code{maf.data = NULL}.
#'
#' @param ld.threshold (optional, double) The threshold to prune SNP based on
#' Long Distance Linkage Disequilibrium.
#' Default: \code{ld.threshold = NULL}.

#' @param filename (optional, character) File name prefix for file written in
#' the working directory.
#' Default: \code{filename = NULL}.


#' @param ... (optional) Advance mode that allows to pass further arguments
#' for fine-tuning the function (see details).

#' @inheritParams tidy_genomic_data

#' @export
#' @rdname snp_ld


#' @importFrom stringi stri_replace_all_fixed stri_join
#' @importFrom tibble has_name
#' @importFrom dplyr select distinct group_by sample_n summarise semi_join n_distinct

#' @references Zheng X, Levine D, Shen J, Gogarten SM, Laurie C, Weir BS.
#' (2012) A high-performance computing toolset for relatedness and principal component
#' analysis of SNP data. Bioinformatics. 28: 3326-3328.
#' doi:10.1093/bioinformatics/bts606

#' @details The function requires \href{https://github.com/zhengxwen/SNPRelate}{SNPRelate}
#' (see example below on how to install).
#'
#'
#' \strong{Advance mode, using \emph{dots-dots-dots}}
#' \itemize{
#' \item \code{long.ld.missing} (logical) With \code{long.ld.missing = TRUE}.
#' The function first generates long distance LD values between markers with
#' \emph{SNPRelate::snpgdsLDMat}.
#' SNPs in LD will be pruned based on
#' missingness.
#' e.g. if 4 SNPs are in LD, the 1 SNP selected in
#' the end is base on genotyping rate/missingness. If this statistic is equal
#' between the SNPs in LD, 1 SNP is chosen randomly.
#'
#' Using missigness add extra computational time. To speed the analysis when
#' missingness between markers is not an issue, use \code{long.ld.missing = FALSE}.
#' The function will use \emph{SNPRelate::snpgdsLDpruning}
#' to prune the dataset. SNPs in LD are selected randomly.
#' Default: \code{long.ld.missing = FALSE}.
#' \item \code{keep.gds} (logical) Default: \code{keep.gds = FALSE}, when the input data is a
#' tidy data frame of genotypes, the GDS file
#' generated for the long distance LD is removed after completion. With GDS input,
#' the GDS file is always updated and kept in the working directory.
#' \item \code{ld.figures}: (logical) Generate long distance LD statistics and
#' figures.
#' Default: \code{ld.figures = FALSE}
#' \item \code{ld.wide}: (logical) Generate a tibble with the pairwise LD values
#' observed between markers in wide format.
#' Default: \code{ld.wide = FALSE}
#' \item \code{ld.tibble}: (logical) Generate a tibble with the pairwise LD
#' values observed between markers in one column (long format).
#' Default: \code{ld.tibble = FALSE}
#' }
#'
#' @return A list in the global environment, with these objects:
#' \enumerate{
#' \item $ld.wide: a tibble with the pairwise LD values observed between markers in wide format.
#' \item $ld.tibble: a tibble with the pairwise LD values observed between markers in one column (long format).
#' \item $ld.summary: tibble with LD statistics used for the boxplot
#' \item $ld.boxplot: box plot of LD values
#' \item $whitelist.snp.ld: whitelist of markers kept after filtering for LD.
#' The argument \code{ld.threshold} must be used to generate the whitelist.
#' \item $blacklist.snp.ld: blacklist of markers prunned during the filtering
#' for LD.
#' The argument \code{ld.threshold} must be used to generate the blacklist.
#' \item $data: The filtered tidy dataset.
#' \item $gds: the path to the GDS file.
#' }

#' @examples
#' \dontrun{
#' #require(SNPRelate)
#' #To install SNPRelate:
#' #source("https://bioconductor.org/biocLite.R")
#' #biocLite("SNPRelate")
#' #library(radiator)
#' data <- radiator::tidy_vcf(
#' data = "my.vcf", strata = "my.strata.tsv",
#' vcf.metadata = FALSE, vcf.stats = TRUE, verbose = TRUE)
#'
#' # short distance LD, no long distance LD:
#' check.short.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf")
#'
#' # short distance LD and long distance LD:
#' pruned.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf", ld.threshold = 0.8)
#' }


#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}


snp_ld <- function(
  data,
  snp.ld = "maf",
  maf.data = NULL,
  ld.threshold = NULL,
  parallel.core = parallel::detectCores() - 1,
  filename = NULL,
  ...
) {

  # # testing
  # data <- res$vcf.connection
  # snp.ld = "maf"
  # maf.data = NULL
  # ld.threshold = 0.8
  # filename = NULL
  # parallel.core = parallel::detectCores() - 1
  # # ...
  # keep.gds <- TRUE
  # ld.figures <- TRUE
  # ld.wide <- FALSE
  # ld.tibble <- FALSE
  # manhattan.plot <- FALSE
  # long.ld.missing = FALSE

  timing <- proc.time()
  opt.change <- getOption("width")
  options(width = 70)
  res.snp.ld <- list()# to store the output

  # dotslist -------------------------------------------------------------------
  radiator.dots <- list(...)
  want <- c("long.ld.missing", "keep.gds", "ld.wide", "ld.tibble", "ld.figures", "manhattan.plot")
  unknowned_param <- setdiff(names(radiator.dots), want)

  if (length(unknowned_param) > 0) {
    stop("Unknowned \"...\" parameters ",
         stringi::stri_join(unknowned_param, collapse = " "))
  }

  long.ld.missing <- radiator.dots[["long.ld.missing"]]
  keep.gds <- radiator.dots[["keep.gds"]]
  ld.wide <- radiator.dots[["ld.wide"]]
  ld.tibble <- radiator.dots[["ld.tibble"]]
  ld.figures <- radiator.dots[["ld.figures"]]
  manhattan.plot <- radiator.dots[["manhattan.plot"]]

  if (is.null(long.ld.missing)) long.ld.missing <- FALSE
  if (is.null(keep.gds)) keep.gds <- FALSE
  if (is.null(ld.wide)) ld.wide <- FALSE
  if (is.null(ld.tibble)) ld.tibble <- FALSE
  if (is.null(ld.figures)) ld.figures <- FALSE
  if (is.null(manhattan.plot)) manhattan.plot <- FALSE
  if (is.null(ld.threshold)) long.ld.missing <- FALSE

  # match arg ------------------------------------------------------------------
  snp.ld <- match.arg(snp.ld, c("first", "random", "last", "middle", "maf"))

  # Checking for missing and/or default arguments ------------------------------
  if (missing(data)) stop("Input file missing")

  # Filename -------------------------------------------------------------------
  file.date <- format(Sys.time(), "%Y%m%d@%H%M")
  if (is.null(filename)) {
    write.ld <- FALSE
    filename <- stringi::stri_join("radiator_", file.date, ".ld")
  } else {
    write.ld <- TRUE
    filename.problem <- file.exists(filename)
    if (filename.problem) {
      filename <- stringi::stri_join(filename, "_", file.date, ".ld")
    } else {
      filename <- stringi::stri_join(filename, ".ld")
    }
  }

  filename.gds <- stringi::stri_join(filename, ".gds")
  # Import data ---------------------------------------------------------------
  data.type <- radiator::detect_genomic_format(data)

  if (data.type == "tbl_df") {
    if (is.vector(data)) {
      data <- radiator::tidy_wide(data = data, import.metadata = FALSE)
    }

    markers <- dplyr::select(data, MARKERS, CHROM, LOCUS, POS) %>%
      dplyr::distinct(MARKERS, .keep_all = TRUE)

    # Check that fiel format as ID and POS -------------------------------------
    if (!tibble::has_name(data, "LOCUS") && !tibble::has_name(data, "POS")) {
      stop("snp.ld is only available for VCF file and/or files with ID and POS info")
    }

    if (!is.null(ld.threshold)) {# for long distance LD pruning
      # Check that snprelate is installed
      if (!requireNamespace("SNPRelate", quietly = TRUE)) {
        stop('To install SNPRelate:\n
         source("https://bioconductor.org/biocLite.R")
         biocLite("SNPRelate")')
      }
      # Check if data is biallelic -------------------------------------------------
      biallelic <- radiator::detect_biallelic_markers(data = data)
      if (!biallelic) stop("Long distance LD: biallelic genotypes required")

      # Generating SNPRelate data --------------------------------------------------
      message("Preparing the data...")
      res.snp.ld$data.gds <- radiator::write_snprelate(
        data = data,
        biallelic = TRUE,
        filename = filename,
        verbose = FALSE)
      if (keep.gds) {
        message("SNPRelate GDS file generated: ", filename.gds)
        message("To close the connection use SNPRelate::snpgdsClose(filename)")
      }
    }
  } else {
    res.snp.ld$data.gds <- data
    data <- markers <- tibble::tibble(
      VARIANT_ID = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/VARIANT_ID")),
      MARKERS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/MARKERS")),
      CHROM = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/CHROM")),
      LOCUS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/LOCUS")),
      POS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/POS"))
    )
  }

  message("Minimizing short distance LD...")
  message("    snp.ld = ", snp.ld)

  snp.locus <- dplyr::distinct(data, LOCUS, MARKERS, .keep_all = TRUE) %>%
    dplyr::arrange(LOCUS, MARKERS)
  locus.stats <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
    dplyr::tally(.) %>%
    dplyr::rename(SNP_N = n) %>%
    dplyr::group_by(SNP_N) %>%
    dplyr::tally(.)

  if (nrow(locus.stats) > 1) {
    range.number.snp.locus <- range(locus.stats$SNP_N, na.rm = TRUE)
    message("    The range in the number of SNP/locus is: ", stringi::stri_join(range.number.snp.locus, collapse = "-"))
    # Random selection ---------------------------------------------------------
    if (snp.ld == "random") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::sample_n(tbl = ., size = 1, replace = FALSE)
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp random

    # Fist SNP on the read -----------------------------------------------------
    if (snp.ld == "first") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = min(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp first

    # Last SNP on the read -----------------------------------------------------
    if (snp.ld == "last") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = max(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp last

    # Middle SNP on the read -----------------------------------------------------
    if (snp.ld == "middle") {
      snp.locus.prep <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.)

      pick.middle <- snp.locus.prep %>%
        dplyr::filter(n > 2) %>%
        dplyr::select(LOCUS)

      if (nrow(pick.middle) == 0) {
        message("IMPORTANT: the data doesn't have more than 3 SNPs per locus")
        message("    First SNP will be selected instead...")
        snp.select <- snp.locus %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))
      } else {

        # For locus with <= 2 SNPs/read just keep the first one.
        keep.first <- snp.locus.prep %>%
          dplyr::filter(n <= 2) %>%
          dplyr::select(LOCUS)
        message("    Number of locus with first SNP selected: ", nrow(keep.first))
        keep.first.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% keep.first$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))

        pick.middle.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% pick.middle$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::filter(POS != min(POS)) %>% # remove the first SNP
          dplyr::filter(POS != max(POS)) %>% # remove the last SNP
          dplyr::sample_n(tbl = ., size = 1, replace = FALSE) # pick one at random

        message("    Number of locus with random middle SNP selected: ", nrow(pick.middle))
        snp.select <- dplyr::bind_rows(keep.first.select, pick.middle.select) %>%
          dplyr::arrange(LOCUS, POS)
      }
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp middle

    # SNP with max MAF on the read -----------------------------------------------
    if (snp.ld == "maf") {
      # snp.select: markers that doesnt require filtering for MAF/MAC
      # because only 1 SNP/locus
      snp.select <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.) %>%
        dplyr::filter(n == 1) %>%
        dplyr::left_join(snp.locus, by = "LOCUS") %>%
        dplyr::select(-n) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE)


      if (is.null(maf.data)) {
        if (data.type == "tbl_df") {
          # calculate GLOBAL MAF per SNP/LOCUS
          if (tibble::has_name(data, "GT_BIN")) {
            markers.df <- dplyr::distinct(snp.locus, MARKERS) %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
            n.markers <- nrow(markers.df)

            global_maf <- function(x) {
              maf.data <- dplyr::group_by(x, MARKERS) %>%
                dplyr::summarise(
                  N = as.numeric(2 * n()),
                  PP = as.numeric(2 * length(GT_BIN[GT_BIN == 0])),
                  PQ = as.numeric(length(GT_BIN[GT_BIN == 1])),
                  QQ = as.numeric(2 * length(GT_BIN[GT_BIN == 2]))
                ) %>%
                # need this step because seen cases where 2 is not the minor allele...
                dplyr::mutate(
                  PP = PP + PQ,
                  QQ = QQ + PQ,
                  ALT = dplyr::if_else(PP < QQ, PP, QQ)) %>%
                dplyr::mutate(
                  MAF_GLOBAL = (ALT / N),
                  N = NULL, PP = NULL, QQ = NULL, PQ = NULL, ALT = NULL) %>%
                dplyr::ungroup(.)

              return(maf.data)
            }#End global_maf

            if (n.markers > 10000) {
              split.vec <- markers.df %>%
                dplyr::mutate(SPLIT_VEC = split_vec_row(
                  markers.df,
                  cpu.rounds = ceiling(n.markers/10000),
                  parallel.core = parallel.core))

              maf.data <- data %>%
                dplyr::filter(!is.na(GT_BIN)) %>%
                dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
                dplyr::left_join(split.vec, by = "MARKERS") %>%
                split(x = ., f = .$SPLIT_VEC) %>%
                .radiator_parallel_mc(
                  X = .,
                  FUN = global_maf,
                  mc.cores = parallel.core
                ) %>%
                dplyr::bind_rows(.)
              markers.df <- split.vec <- NULL
            } else {
              maf.data <- global_maf(
                x = dplyr::filter(data, !is.na(GT_BIN)) %>%
                  dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
              )
            }
          } else {
            maf.data <- data %>%
              dplyr::filter(GT != "000000") %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
              dplyr::select(MARKERS, INDIVIDUALS, GT) %>%
              dplyr::mutate(
                A1 = stringi::stri_sub(GT, 1, 3),
                A2 = stringi::stri_sub(GT, 4,6)
              ) %>%
              dplyr::select(MARKERS, INDIVIDUALS, A1, A2) %>%
              tidyr::gather(data = ., key = ALLELES, value = GT, -c(MARKERS, INDIVIDUALS)) %>%
              dplyr::group_by(MARKERS, GT) %>%
              dplyr::tally(.) %>%
              dplyr::group_by(MARKERS) %>%
              dplyr::mutate(n.al.tot = sum(n)) %>%
              dplyr::filter(n == min(n)) %>%
              dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
              dplyr::summarise(MAF_GLOBAL = n / n.al.tot) %>%
              dplyr::ungroup(.) %>%
              dplyr::select(MARKERS, MAF_GLOBAL)
          }

          snp.select.maf <- snp.locus %>%
            dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
            dplyr::left_join(maf.data, by = "MARKERS") %>%
            dplyr::group_by(LOCUS) %>%
            dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
            dplyr::ungroup(.) %>%
            dplyr::distinct(LOCUS, .keep_all = TRUE)

        } else {
          # Note to myself: instead of creating a new object (maf.data),
          # include the info in the markers obj
          n.markers <- dplyr::n_distinct(markers$MARKERS)
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                SeqArray::seqAlleleCount(
                  gdsfile = res.snp.ld$data.gds,
                  ref.allele = NULL,
                  .progress = TRUE,
                  parallel = parallel.core) %>%
                  unlist(.) %>%
                  matrix(
                    data = .,
                    nrow = n.markers, ncol = 2, byrow = TRUE,
                    dimnames = list(rownames = markers$MARKERS,
                                    colnames = c("REF_COUNT", "ALT_COUNT"))) %>%
                  tibble::as_tibble(.)) %>%
              dplyr::mutate(
                # MAC or MAF here it's the same
                MAF_GLOBAL = dplyr::if_else(ALT_COUNT < REF_COUNT, ALT_COUNT, REF_COUNT),
                ALT_COUNT = NULL,
                REF_COUNT = NULL)
          )
        }
      } else {
        if (is.vector(maf.data)) {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                readr::read_tsv(
                  file = maf.data,
                  col_types = readr::cols(.default = readr::col_character())) %>%
                  dplyr::select(MARKERS, MAF_GLOBAL) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)
              ))
        } else {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                maf.data %>%
                  dplyr::select(dplyr::one_of(c("MARKERS", "MAF_GLOBAL"))) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)))
        }
      }
      # alternative that doesnt require snp.select.maf
      snp.select <- markers %>%
        dplyr::filter(!MARKERS %in% snp.select$MARKERS) %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
        dplyr::ungroup(.) %>%
        dplyr::select(-MAF_GLOBAL) %>%
        dplyr::distinct(LOCUS, .keep_all = TRUE) %>%
        dplyr::bind_rows(snp.select)

      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = "/")
      message("    Number of markers before/blacklisted/after: ", n.markers)
      snp.locus <- markers <- NULL
    }#End snp maf


    # filtering the VCF to minimize LD -----------------------------------------
    # data <- dplyr::semi_join(data, snp.select, by = c("LOCUS", "POS"))
    if (data.type == "tbl_df") {
      data <- dplyr::filter(data, MARKERS %in% snp.select$MARKERS)
    } else {
      res.snp.ld$whitelist.snp.ld <- snp.select
      res.snp.ld$blacklist.snp.ld <- dplyr::filter(data, !MARKERS %in% snp.select$MARKERS)
      data <- res.snp.ld$whitelist.snp.ld

      # updating the GDS object ------------------------------------------------
      SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
                             variant.id = data$VARIANT_ID,
                             verbose = FALSE)

    }
    message("    Filtering the dataset to minimize LD by keeping only 1 SNP per locus")
  } else {
    message("    There is no variation in the number of SNP/locus across the data")
    data <- res.snp.ld$whitelist.snp.ld <- snp.locus
    res.snp.ld$blacklist.snp.ld <- NULL
  }
  # Note to myself:
  # locus.stats: this stats could be written in directory or output in res
  snp.select <-  locus.stats <- NULL


  # Long distance LD pruning ---------------------------------------------------

  if (!is.null(ld.threshold)) {
    # updating GDS object
    want <- c("VARIANT_ID", "MARKERS", "CHROM", "LOCUS", "POS")
    markers <- variant.id.select <- suppressWarnings(
      dplyr::select(data, dplyr::one_of(want)) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
        dplyr::arrange(VARIANT_ID))


    # # Test with 10000 markers
    # random.markers <- 5000
    # markers <- variant.id.select <- dplyr::sample_n(
    #   tbl = variant.id.select, size = random.markers) %>%
    #   dplyr::arrange(VARIANT_ID)

    variant.id.select <- variant.id.select %>%
      dplyr::select(VARIANT_ID) %>%
      purrr::flatten_int(.)

    # Apply the filter on the gds ...
    # SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
    #                        variant.id = variant.id.select, verbose = FALSE)
    n.markers <- length(variant.id.select)
    if (long.ld.missing) {
      message("Long distance LD pruning with missing data")
      message("Computing LD by  CHROM/scaffold...")
      chrom.select <- markers %>% split(x = ., f = .$CHROM)
      # chrom.select <- chrom.select[1:10]
      # chrom.select <- chrom.select[[9]]
      ld_chrom_missing <- function(chrom.select, x, data.type) {
        message("Chrom: ", unique(chrom.select$CHROM))
        message("    number SNPs: ", length(chrom.select$VARIANT_ID))
        # save the filters------------------------------------------------------
        w.m <- SeqArray::seqGetData(x, "variant.id")
        w.s <- SeqArray::seqGetData(x, "sample.id")

        # Adjusting the parallel.core argument ---------------------------------
        # SNPRelate doesnt like when lower than number of markers used...
        parallel.core.temp <- max(1L, length(chrom.select$MARKERS))
        if (parallel.core <= parallel.core.temp) {
          parallel.core.temp <- parallel.core
        }

        if (nrow(chrom.select) > 1) {
          res.chrom <- SNPRelate::snpgdsLDMat(
            gdsobj = x,
            snp.id = chrom.select$VARIANT_ID,
            sample.id = w.s,
            slide = -1,
            mat.trim = FALSE,
            method = "r", #composite and corr option are the same with 0, 1, 2 gt coding
            num.thread = parallel.core.temp,
            with.id = TRUE,
            verbose = FALSE) %$%
            LD %>%
            magrittr::set_colnames(x = ., chrom.select$MARKERS) %>%
            magrittr::set_rownames(x = ., chrom.select$MARKERS)

          # The function SNPRelate::snpgdsLDMat also set the filter
          # to the chosen markers and samples...
          # check <- SeqArray::seqGetFilter(x)
          # length(check$sample.sel[check$sample.sel])
          # length(check$variant.sel[check$variant.sel])
          # n.markers


          # work on the output ---------------------------------------------------------
          # long.distance.ld <- long.distance.ld^2

          # Full matrix
          # if (ld.wide) {
          #   # generate a tibble
          #   filename.ld.wide <- stringi::stri_join(filename, ".wide")
          #   message("Writing LD wide tibble file: ", filename.ld.wide)
          #   radiator::write_rad(
          #     data = dplyr::bind_cols(tibble::data_frame(
          #       MARKERS_A = rownames(res.snp.ld$ld.tibble)),
          #       tibble::as_data_frame(res.snp.ld$ld.tibble)),
          #     path = filename.ld.wide)
          # }

          # LD tibble long...
          # Here we want the tibble in long format with LD values in one column
          # message("Generating LD tibble...")
          # we don't need the full matrix
          res.chrom[lower.tri(res.chrom, diag = TRUE)] <- rlang::na_dbl

          # stats and figures----------------------------------------------------------------------
          # if (ld.figures) {
          #   message("Generating statistics")
          #   res.snp.ld$ld.summary <- tibble::tibble(
          #     LD = as.vector(res.snp.ld$ld.tibble[!is.na(res.snp.ld$ld.tibble)])) %>%
          #     dplyr::summarise(
          #       MIN = min(LD, na.rm = TRUE),
          #       Q25 = stats::quantile(LD, 0.25, na.rm = TRUE),
          #       MEDIAN = stats::median(LD, na.rm = TRUE),
          #       Q75 = stats::quantile(LD, 0.75, na.rm = TRUE),
          #       MAX = max(LD, na.rm = TRUE),
          #       IQR = stats::IQR(LD, na.rm = TRUE)
          #     ) %>%
          #     dplyr::mutate(
          #       OUTLIERS_LOW = Q25 - (1.5 * IQR),
          #       OUTLIERS_HIGH =  Q75 + (1.5 * IQR),
          #       GROUP = 1
          #     )
          #
          #   if (res.snp.ld$ld.summary$OUTLIERS_LOW < 0) {
          #     res.snp.ld$ld.summary$OUTLIERS_LOW <- res.snp.ld$ld.summary$MIN
          #   }
          #
          #   message("Generating figures...")
          #   res.snp.ld$ld.boxplot <- boxplot_stats(
          #     data = res.snp.ld$ld.summary,
          #     title = "Markers long distance linkage disequilibrium (LD)",
          #     x.axis.title = NULL,
          #     y.axis.title = "Long distance linkage disequilibrium (r)",
          #     bp.filename = "ld.boxplot.pdf")
          #
          #   # res.snp.ld$ld.no.outliers.tibble <- dplyr::filter(res.snp.ld$ld.tibble, LD < res.snp.ld$ld.summary$OUTLIERS_HIGH & LD > res.snp.ld$ld.summary$OUTLIERS_LOW)
          #
          #   # Note to myself : interesting but not sure worth the time exploring...
          #
          #
          #   # res.snp.ld$ld.no.outliers.summary <- tibble::tibble(
          #   #   x = 1,
          #   #   MIN = min(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
          #   #   Q25 = stats::quantile(res.snp.ld$ld.no.outliers.tibble$LD, 0.25, na.rm = TRUE),
          #   #   MEDIAN = stats::median(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
          #   #   Q75 = stats::quantile(res.snp.ld$ld.no.outliers.tibble$LD, 0.75, na.rm = TRUE),
          #   #   MAX = max(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
          #   #   IQR = stats::IQR(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
          #   #   OUTLIERS_LOW = Q25 - (1.5 * IQR),
          #   #   OUTLIERS_HIGH =  Q75 + (1.5 * IQR)
          #   # )
          #   # if (res.snp.ld$ld.no.outliers.summary$OUTLIERS_LOW < 0) res.snp.ld$ld.no.outliers.summary$OUTLIERS_LOW <- res.snp.ld$ld.no.outliers.summary$MIN
          #   #
          #   # element.text <- ggplot2::element_text(size = 10,
          #   #                                       family = "Helvetica", face = "bold")
          #   #
          #   # res.snp.ld$ld.boxplot.no.outliers <- ggplot2::ggplot(
          #   #   data = res.snp.ld$ld.no.outliers.summary, ggplot2::aes(x)) +
          #   #   ggplot2::geom_boxplot(
          #   #     ggplot2::aes(ymin = MIN, lower = Q25, middle = MEDIAN,
          #   #                  upper = Q75, ymax = MAX), stat = "identity") +
          #   #   ggplot2::labs(
          #   #     y = "Long distance linkage disequilibrium",
          #   #     title = "Markers long distance linkage disequilibrium (LD)") +
          #   #   ggplot2::theme_bw() +
          #   #   ggplot2::theme(
          #   #     plot.title = ggplot2::element_text(size = 12, family = "Helvetica", face = "bold", hjust = 0.5),
          #   #     legend.position = "none",
          #   #     axis.title.x = ggplot2::element_blank(),
          #   #     axis.title.y = element.text,
          #   #     axis.text.x = ggplot2::element_blank(),
          #   #     axis.ticks.x = ggplot2::element_blank()
          #   #   )
          #   # element.text <- NULL
          #   # print(res.snp.ld$ld.boxplot.no.outliers)
          #   # suppressMessages(ggplot2::ggsave(
          #   #   filename = "ld.no.outliers.boxplot.pdf",
          #   #   # filename = file.path(path.folder.coverage, "plot.coverage.boxplot.pdf"),
          #   #   plot = res.snp.ld$ld.boxplot.no.outliers,
          #   #   width = 15, height = 20,
          #   #   dpi = 300, units = "cm", useDingbats = FALSE))
          #
          #
          #   # res.snp.ld$ld.manhattan.plot
          #   # if (manhattan.plot) {
          #   #   res.snp.ld$ld.manhattan.plot <- res.snp.ld$ld.tibble %>%
          #   #     # dplyr::mutate(X = "1") %>%
          #   #     dplyr::group_by(LD) %>%
          #   #     dplyr::tally(.) %>%
          #   #     dplyr::ungroup(.) %>%
          #   #     dplyr::mutate(X = "1") %>%
          #   #     ggplot2::ggplot(data = .,
          #   #                     ggplot2::aes(x = X, y = LD, size = n)) +
          #   #     ggplot2::geom_jitter(alpha = 0.3, stat = "identity") +
          #   #     ggplot2::labs(y = "LD") +
          #   #     ggplot2::scale_size_area(name = "Pairs of markers", max_size = 6) +
          #   #     ggplot2::theme_light() +
          #   #     ggplot2::theme(
          #   #       # legend.position = "none",
          #   #       panel.grid.minor.x = ggplot2::element_blank(),
          #   #       panel.grid.major.x = ggplot2::element_blank(),
          #   #       # panel.grid.major.y = element_blank(),
          #   #       axis.title.x = ggplot2::element_blank(),
          #   #       axis.text.x = ggplot2::element_blank(),
          #   #       axis.title.y = ggplot2::element_text(size = 10, family = "Helvetica", face = "bold"),
          #   #       axis.text.y = ggplot2::element_text(size = 8, family = "Helvetica")
          #   #     )
          #   #
          #   #   suppressMessages(ggplot2::ggsave(
          #   #     filename = "ld.manhattan.plot.png",
          #   #     plot = res.snp.ld$ld.manhattan.plot,
          #   #     width = 15, height = 20,
          #   #     dpi = 100, units = "cm"#useDingbats = FALSE
          #   #   ))
          #   # }
          # }#End ld.figures

          # Generate the missingness stats -----------------------------------------
          # message("Generate missingness stats")
          if (data.type == "tbl_df") {
            if (tibble::has_name(x, "GT")) {
              markers.missing <- dplyr::filter(x, GT != "000000") %>%
                dplyr::group_by(MARKERS) %>%
                dplyr::summarise(GENOTYPED_PROP = length(GT) / n.ind)
            } else {
              markers.missing <- dplyr::filter(x, !is.na(GT_BIN)) %>%
                dplyr::group_by(MARKERS) %>%
                dplyr::summarise(GENOTYPED_PROP = length(GT_BIN) / n.ind)
            }
          } else {
            markers.missing <- tibble::tibble(
              MARKERS = chrom.select$MARKERS,
              MISSING_PROP = SeqArray::seqMissing(
                gdsfile = x,
                per.variant = TRUE, .progress = TRUE, parallel = parallel.core.temp)) %>%
              dplyr::mutate(GENOTYPED_PROP = 1 - MISSING_PROP, MISSING_PROP = NULL)
          }

          # Pruning the SNPs -------------------------------------------------------
          # message("Pruning markers in long distance LD...")

          # These LD values are not used anyway during the pruning
          res.chrom[res.chrom <= ld.threshold] <- rlang::na_dbl
          # remove rows and cols with all missing values
          res.chrom <- res.chrom[rowSums(res.chrom, na.rm = TRUE) > 0, colSums(res.chrom, na.rm = TRUE) > 0, drop = FALSE]

          if (length(res.chrom) >= 1) {
            res.chrom <- ld2df(x = res.chrom)
            ld.markers <- ld_pruning(
              ld.tibble = res.chrom,
              stats = markers.missing,
              ld.threshold = ld.threshold
            )
          } else {
            message("    with LD threshold: ", ld.threshold, " SNPs blacklisted: 0")
            ld.markers$blacklist.markers <- NULL
          }
        } else {
          message("    with LD threshold: ", ld.threshold, " SNPs blacklisted: 0")
          ld.markers$blacklist.markers <- NULL
        }
        # Reset the filter of the GDS-------------------------------------------
        SeqArray::seqSetFilter(object = x, variant.id = w.m, sample.id = w.s,
                               verbose = FALSE)
        return(ld.markers$blacklist.markers)
      }#End ld_chrom_missing

      # message("Pruning markers in long distance LD...")
      chrom.ld <- purrr::map_df(.x = chrom.select,
                                .f = ld_chrom_missing,
                                x = res.snp.ld$data.gds,
                                data.type = data.type)

      # message("Generating whitelist and blacklist of markers")
      markers %<>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            MARKERS %in% chrom.ld$MARKERS, FALSE, TRUE))
      chrom.ld <- NULL
      res.snp.ld$whitelist.snp.ld <- dplyr::filter(markers, FILTER_LONG_LD)
      message("    Number of SNPs after pruning for long distance LD: ",
              nrow(res.snp.ld$whitelist.snp.ld))

      res.snp.ld$blacklist.snp.ld <- dplyr::filter(markers, !FILTER_LONG_LD)

      message("    Number of prunned SNPs based on long distance LD: ",
              nrow(res.snp.ld$blacklist.snp.ld))

      # updating the GDS object ------------------------------------------------
      if (data.type == "tbl_df") {
        data <- dplyr::filter(data, MARKERS %in% res.snp.ld$whitelist.snp.ld$MARKERS)
      } else {
        SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
                               variant.id = res.snp.ld$whitelist.snp.ld$VARIANT_ID,
                               verbose = TRUE)
      }

    } else {
      # Pruning with SNPRelate::snpgdsLDpruning --------------------------------------
      # problem with this one is that missigness is unaccounted for during SNP selection
      # SNPs are randomly selected...
      message("Long distance LD pruning WITHOUT missing data stats")
      # ld.threshold <- 0.8
      ld.markers <- list()

      # TODO:
      # parallelize with and without the use of missing
      # with SNPRelate::snpgdsLDpruning, split a whitelist of markers based
      # on chromosome

      # So far test shows that there's no gain in speed to do it in parallel
      # more test with different datasets required (tested 2...)
      # n.chrom <- dplyr::n_distinct(markers$CHROM)

      # if (parallel.core > 1) {
      # prune_ld_par <- function(chrom.snp.select, data, threshold) {
      # pruned.snp <- SNPRelate::snpgdsLDpruning(
      #   gdsobj = data,
      #   snp.id = chrom.snp.select$VARIANT_ID,
      #   autosome.only = FALSE,
      #   remove.monosnp = TRUE,
      #   maf = NaN,
      #   missing.rate = NaN,
      #   method = "r",
      #   ld.threshold = threshold,
      #   num.thread = 1,
      #   verbose = TRUE) %>%
      #   purrr::flatten_int(.)
      # return(pruned.snp)
      # }#End prune_ld_par
      #

      # ld.markers$whitelist.markers <-
      #   split(x = x, f = split.vec) %>%
      #   .radiator_parallel(
      #     X = ., FUN = clean, mc.cores = parallel.core) %>%
      #   purrr::flatten_int(.)

      # sample.chrom <- sample(x = unique(markers$CHROM), size = 11)
      #
      # check <- dplyr::left_join(
      #   dplyr::select(markers, CHROM, VARIANT_ID),
      #   dplyr::distinct(markers, CHROM) %>%
      #     dplyr::mutate(
      #       SPLIT_VEC = split_vec_row(x = ., cpu.rounds = 10, parallel.core = parallel.core)
      #     )
      #   , by = "CHROM") %>%
      #   dplyr::filter(CHROM %in% sample.chrom) %>%
      #   dplyr::select(-CHROM) %>%
      #   split(x = ., f = .$SPLIT_VEC) %>%
      #   .radiator_parallel_mc(
      #     X = .,
      #     FUN = prune_ld_par,
      #     mc.cores = parallel.core,
      #     data = res.snp.ld$data.gds, threshold = ld.threshold
      #   ) %>%
      #   purrr::flatten_int(.)
      # length(unique(check$CHROM))


      ld.markers$whitelist.markers <- SNPRelate::snpgdsLDpruning(
        gdsobj = res.snp.ld$data.gds,
        snp.id = variant.id.select,
        sample.id = SeqArray::seqGetData(res.snp.ld$data.gds, "sample.id"),
        autosome.only = FALSE,
        remove.monosnp = TRUE,
        maf = NaN,
        missing.rate = NaN,
        method = "r",
        ld.threshold = ld.threshold,
        num.thread = 1,
        verbose = FALSE) %>%
        purrr::flatten_int(.)

      ld.markers$blacklist.markers <- purrr::keep(
        .x = variant.id.select,
        .p = !variant.id.select %in% ld.markers$whitelist.markers)
      markers <- markers %>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            VARIANT_ID %in% ld.markers$whitelist.markers, TRUE, FALSE))
      ld.markers <- NULL
      res.snp.ld$whitelist.snp.ld <- dplyr::filter(markers, FILTER_LONG_LD)
      message("    Number of SNPs after pruning for long distance LD: ",
              nrow(res.snp.ld$whitelist.snp.ld))

      res.snp.ld$blacklist.snp.ld <- dplyr::filter(markers, !FILTER_LONG_LD)

      message("    Number of prunned SNPs based on long distance LD: ",
              nrow(res.snp.ld$blacklist.snp.ld))

      # updating the GDS object ------------------------------------------------
      if (data.type == "tbl_df") {
        data <- dplyr::filter(data, MARKERS %in% res.snp.ld$whitelist.snp.ld$MARKERS)
      } else {
        SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
                               variant.id = res.snp.ld$whitelist.snp.ld$VARIANT_ID,
                               verbose = FALSE)

      }
    }
  }#End long distance LD pruning

  message("    Generating whitelist and blacklist of markers")
  message("\nComputation time for LD: ", round((proc.time() - timing)[[3]]), " sec")
  options(width = opt.change)

  if (data.type == "tbl_df") {
    return(data)
  } else {
    return(res.snp.ld)
  }
}#End snp_ld


# Internal nested functions: ---------------------------------------------------

# melt the LD matrice into a data frame --------------------------------------
#' @title ld2df
#' @description melt the LD matrice into a data frame
#' @rdname ld2df
#' @export
#' @keywords internal
ld2df <- function(x) {
  # x <- ld.upper.matrix
  x <- as.matrix(x)
  # diag(x) <- NA
  # x[lower.tri(x)] <- NA
  x <- dplyr::bind_cols(tibble::data_frame(MARKERS_A = rownames(x)),
                        tibble::as_data_frame(x)) %>%
    data.table::as.data.table(.) %>%
    data.table::melt.data.table(
      data = ., id.vars = "MARKERS_A", variable.name = "MARKERS_B", value.name = "LD",
      variable.factor = FALSE) %>%
    tibble::as_data_frame(.) %>%
    dplyr::filter(!is.na(LD)) %>%
    dplyr::arrange(dplyr::desc(LD))
  return(x)
}#End distance2df

# ld_pruning  ------------------------------------------------------------------

#' @name ld_pruning
#' @title Prune dataset based on LD.
#' @description Used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' Prune dataset based on LD. Use missingness to keep 1 SNP.

#' @param ld.tibble (path) The markers LD pairwise data.
#' Default: \code{ld.tibble = NULL}.
#' @param stats (path) The markers missingness info statistics.
#' Default: \code{stats = NULL}.
#' @param ld.threshold (double) The threshold to prune SNPs in LD.
#' Default: \code{ld.threshold = 0.8}.

#' @return A list with blacklisted SNPs.  Write the blacklist in the working
#' directory.
#' @export
#' @keywords internal
#' @rdname remove_duplicates
#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}

ld_pruning <- function(
  ld.tibble = NULL,
  stats = NULL,
  ld.threshold = 0.8
) {
  #test
  # ld.tibble = res$ld.tibble
  # stats = res$markers.missing
  # ld.threshold = 0.8

  ld.tibble <- dplyr::filter(ld.tibble, LD > ld.threshold)

  if (nrow(ld.tibble) > 0) {
    markers.ld.list <- tibble::data_frame(
      MARKERS = c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B)) %>%
      dplyr::group_by(MARKERS) %>%
      dplyr::tally(.) %>%
      dplyr::ungroup(.) %>%
      dplyr::arrange(dplyr::desc(n)) %>%
      dplyr::distinct(MARKERS) %>%
      purrr::flatten_chr(.)

    # test <- unique(c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B))
    # we want to have them ordered from highest to lowest hence the appraoch above...

    geno.stats <- dplyr::filter(stats, MARKERS %in% markers.ld.list)

    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)),
                whitelist.markers = tibble::tibble(MARKERS = character(0)))

    for (i in markers.ld.list) {
      # i <- markers.ld.list[1]
      dups <- dplyr::filter(ld.tibble, MARKERS_A %in% i | MARKERS_B %in% i)
      dups <- sort(unique(c(dups$MARKERS_A, dups$MARKERS_B)))

      # find all duplicates associated with the network
      new.dups <- 0L
      while(length(new.dups) > 0) {
        new.dups <- dplyr::filter(ld.tibble, MARKERS_A %in% dups | MARKERS_B %in% dups)
        new.dups <- sort(unique(c(new.dups$MARKERS_A, new.dups$MARKERS_A)))
        new.dups <- purrr::keep(.x = new.dups, .p = !new.dups %in% dups)
        if (length(new.dups) > 0) {
          dups <- c(dups, new.dups)
        }
      }
      dups <- tibble::data_frame(MARKERS = dups)

      if (nrow(res$blacklist.markers) > 0) {
        dups <- dplyr::filter(dups, !MARKERS %in% res$blacklist.markers$MARKERS)
      }

      if (nrow(dups) > 0) {
        whitelist.markers <- dups %>%
          dplyr::left_join(geno.stats, by = "MARKERS") %>%
          dplyr::filter(GENOTYPED_PROP == max(GENOTYPED_PROP)) %>%
          dplyr::sample_n(tbl = ., size = 1) %>% # make sure only 1 is selected
          dplyr::select(MARKERS)

        if (nrow(whitelist.markers) > 0) res$whitelist.markers <- dplyr::bind_rows(res$whitelist.markers, whitelist.markers)

        blacklist.markers <- dplyr::filter(dups, !MARKERS %in% whitelist.markers$MARKERS) %>%
          dplyr::select(MARKERS)

        if (nrow(blacklist.markers) > 0) res$blacklist.markers <- dplyr::bind_rows(res$blacklist.markers, blacklist.markers)
      }
    }
    dups <- blacklist.markers <- whitelist.markers <- i <- new.dups <- NULL
    res$blacklist.markers <- dplyr::distinct(res$blacklist.markers, MARKERS)
    res$whitelist.markers <- NULL
    message("    with LD threshold: ", ld.threshold, " SNPs blacklisted: ", nrow(res$blacklist.markers))

  } else {
    message("    with LD threshold: ", ld.threshold, " SNPs blacklisted: 0")
    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)))
  }
  return(res)
} # End ld_pruning
